{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayveersinh-Raj/Machine_Learning_IU_Labs/blob/main/Lab_3_self_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su3arr6KW-TN"
      },
      "source": [
        "### Lab-3 : Self-Practice\n",
        "\n",
        "#### In this week, your self-practice task will consist to analyze the impact of class imballance on the performance of the logistic regression model.\n",
        "\n",
        "#### Class imbalance is very common in real life. For example, in a classification problem to predict whether a person has a certain very rare disease, the dataset will always contain more negative samples than positive ones. This situation can have a significant impact on the performance of the model. You will analyze this situation in the case of the Titanic dataset used in the lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awQ5it11W-TU"
      },
      "source": [
        "### 1. Load the titanic dataset and <b>PLOT</b> the proportion of positive and negative samples (survived vs non survived)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "rZXUVCT2W-TV",
        "outputId": "9d231bfe-2548-4dae-846d-8b201cc8d0ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f41f9779350>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "### write your code here. Load the dataset and plot (barplot) proportion of each class \n",
        "df = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "# Below dataframe was printed to see the column name of the class\n",
        "# df.head()\n",
        "df[\"survived\"].value_counts().plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.survived.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu2Iu10PkIVU",
        "outputId": "f7c14ff4-5c9a-4110-f53b-3a503b31c7d8"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    809\n",
              "1    500\n",
              "Name: survived, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoriMit5W-TX"
      },
      "source": [
        "#### Preprocess the data as it has been done in the lab, feel free to adapt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC3oFY_YW-TY",
        "outputId": "53a503ae-f539-47ff-dcd0-c63e9995b87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1309 entries, 0 to 1308\n",
            "Data columns (total 9 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   survived  1309 non-null   int64  \n",
            " 1   pclass    1309 non-null   int64  \n",
            " 2   name      1309 non-null   object \n",
            " 3   sex       1309 non-null   object \n",
            " 4   age       1046 non-null   float64\n",
            " 5   sibsp     1309 non-null   int64  \n",
            " 6   parch     1309 non-null   int64  \n",
            " 7   fare      1308 non-null   float64\n",
            " 8   embarked  1307 non-null   object \n",
            "dtypes: float64(2), int64(4), object(3)\n",
            "memory usage: 92.2+ KB\n"
          ]
        }
      ],
      "source": [
        "#### preprocess the data\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `age`, `fare`, and `embarked` has 253, 2, and 1 missing values respectively so imputation is needed too, and we will also apply scaler.\n",
        "\n",
        "## And `name` would be removed as it is not necessary"
      ],
      "metadata": {
        "id": "0w9PtQLLbl0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split(df, test_size_split):\n",
        "\n",
        "   # removing name column\n",
        "   df = df.drop(['name'], axis = 1)\n",
        "   \n",
        "   # find and print the proportion of positive samples in data\n",
        "   print('% of positive samples in whole data:', sum(df['survived'] == 1) / len(df))\n",
        "   \n",
        "   # split data\n",
        "   x_train, x_test, y_train, y_test = train_test_split(df.loc[:, 'pclass':], df['survived'],\n",
        "                                                       test_size=test_size_split, stratify=df['survived'])\n",
        "   \n",
        "   # find and print the proportion of positive samples in train and test sets, make sure they are approx same\n",
        "   print('% of positive samples in train set:', sum(y_train== 1) / len(x_train))\n",
        "   print('% of positive samples in test set:', sum(y_test== 1) / len(x_test))\n",
        "   return x_train, x_test, y_train, y_test"
      ],
      "metadata": {
        "id": "-DDNZetlc2zN"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def impute(x_train, x_test):\n",
        "    # imputing missing values\n",
        "    imputer = SimpleImputer(strategy='most_frequent')\n",
        "    imputer.fit(x_train)\n",
        "    x_train = pd.DataFrame(imputer.transform(x_train), columns=x_train.columns)\n",
        "    x_test = pd.DataFrame(imputer.transform(x_test), columns=x_test.columns)\n",
        "    return x_train, x_test"
      ],
      "metadata": {
        "id": "jYKLtmLpcN-g"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding and scaling"
      ],
      "metadata": {
        "id": "Vnlzy-dpdnnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# one-hot-encode categorical features\n",
        "def ohe_new_features(df, features_name, encoder):\n",
        "    new_feats = encoder.transform(df[features_name])\n",
        "    # create dataframe from encoded features with named columns\n",
        "    new_cols = pd.DataFrame(new_feats, dtype=int, columns=encoder.get_feature_names(features_name))\n",
        "    new_df = pd.concat([df, new_cols], axis=1)    \n",
        "    new_df.drop(features_name, axis=1, inplace=True)\n",
        "    return new_df\n",
        "\n",
        "def encode_scale(x_train, x_test):\n",
        "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "    f_names = ['sex', 'embarked']\n",
        "    encoder.fit(x_train[f_names])\n",
        "    x_train = ohe_new_features(x_train, f_names, encoder)\n",
        "    x_test = ohe_new_features(x_test, f_names, encoder)\n",
        "    \n",
        "    # feature scaling\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(x_train)\n",
        "    x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n",
        "    x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
        "    return x_train, x_test"
      ],
      "metadata": {
        "id": "-46K-TZodsEN"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbxd9U8ZW-TY"
      },
      "source": [
        "## 2. Impact of class imballance. \n",
        "##### Now, you will `artificially` imbalance the dataset. From the original dataset, create different dataset with the following class representations (drop samples from one class): \n",
        "##### 1. 20% vs 80%\n",
        "##### 2. 30% vs 70%\n",
        "##### 3. 40% vs 60%\n",
        "\n",
        "## Split each data into train and test set as in the lab; train logistic regression model for each setting and report (PLOT) the accuracy, precision, and recall of each model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The logistic regression function that prints accuracy, precision, and recall and returns `acccuracy`"
      ],
      "metadata": {
        "id": "prmiBrqnnpCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "def logistic_regression(x_train, x_test, y_train, y_test):\n",
        "    clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
        "    y_test_pred = clf.predict(x_test)\n",
        "    \n",
        "    print('Testing accuracy = {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
        "    print('Testing precision = {}'.format(metrics.precision_score(y_test, y_test_pred)))\n",
        "    print('Testing recall = {}'.format(metrics.recall_score(y_test, y_test_pred)))\n",
        "\n",
        "    return metrics.accuracy_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "1eSIAr_xmuQw"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to drop according to setting ratio provided above"
      ],
      "metadata": {
        "id": "zVMK9KpMo_tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### write your code here \n",
        "def drop_class_setting(drop_percent):\n",
        "    to_be_removed = df[(df.survived == 1)].sample(frac=drop_percent, replace=True, random_state=42)\n",
        "    df_new = df.drop(to_be_removed.index)\n",
        "    print(f\"New 30% dropped class: \\n{df_new.survived.value_counts()}\")\n",
        "    print(f\"\\nOriginal class : \\n{df.survived.value_counts()}\")\n",
        "    return df_new"
      ],
      "metadata": {
        "id": "1KaHdwI3pJ6H"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 20% vs 80%"
      ],
      "metadata": {
        "id": "zkEG1gEiibPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping from class 1 using ratio settings and creating New DataFrame"
      ],
      "metadata": {
        "id": "2FHCcI4dpqUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGS-Zg50W-TZ",
        "outputId": "585c286e-971b-47b0-d1a6-6239f7880116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New 30% dropped class: \n",
            "0    809\n",
            "1    409\n",
            "Name: survived, dtype: int64\n",
            "\n",
            "Original class : \n",
            "0    809\n",
            "1    500\n",
            "Name: survived, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_1 = drop_class_setting(drop_percent=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting new dataframe (train and test), imputing, encoding, and scaling"
      ],
      "metadata": {
        "id": "Eb6qhht_qm3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets split the new dataframe\n",
        "\n",
        "# splitting\n",
        "x_train_1, x_test_1, y_train_1, y_test_1 = split(df_1, 0.2)\n",
        "\n",
        "# imputing\n",
        "x_train1_imputed, x_test1_imputed = impute(x_train_1, x_test_1)\n",
        "\n",
        "# encoding and scaling\n",
        "scaled_x_train1, scaled_x_test1 = encode_scale(x_train1_imputed, x_test1_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6dIzdlHqlH9",
        "outputId": "4a21dd8f-4814-4fd7-88b3-b066957b4560"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of positive samples in whole data: 0.33579638752052543\n",
            "% of positive samples in train set: 0.33572895277207393\n",
            "% of positive samples in test set: 0.3360655737704918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for 1"
      ],
      "metadata": {
        "id": "qPFTOXvJpuwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_1 = logistic_regression(scaled_x_train1, scaled_x_test1, y_train_1, y_test_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBIvzAydpojq",
        "outputId": "0c9932fc-a9c0-4aa9-b984-f48315ee7a6c"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy = 0.819672131147541\n",
            "Testing precision = 0.7375\n",
            "Testing recall = 0.7195121951219512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 30% vs 70%"
      ],
      "metadata": {
        "id": "269l_EXuoa4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping from class 2 using ratio settings and creating New DataFrame"
      ],
      "metadata": {
        "id": "qAQv0bvTwFsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping 30%\n",
        "df_2 = drop_class_setting(drop_percent=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd9jfNXwofF1",
        "outputId": "b423ab9a-f57f-47aa-844a-771113392f95"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New 30% dropped class: \n",
            "0    809\n",
            "1    371\n",
            "Name: survived, dtype: int64\n",
            "\n",
            "Original class : \n",
            "0    809\n",
            "1    500\n",
            "Name: survived, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting new dataframe (train and test), imputing, encoding, and scaling"
      ],
      "metadata": {
        "id": "ra8cMWdtoThn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets split the new dataframe\n",
        "\n",
        "# splitting\n",
        "x_train_2, x_test_2, y_train_2, y_test_2 = split(df_2, 0.2)\n",
        "\n",
        "# imputing\n",
        "x_train2_imputed, x_test2_imputed = impute(x_train_2, x_test_2)\n",
        "\n",
        "# encoding and scaling\n",
        "scaled_x_train2, scaled_x_test2 = encode_scale(x_train2_imputed, x_test2_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8zbYtVhoDmZ",
        "outputId": "67b745f3-4c40-45b2-89ca-03f9402fa388"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of positive samples in whole data: 0.31440677966101693\n",
            "% of positive samples in train set: 0.3146186440677966\n",
            "% of positive samples in test set: 0.3135593220338983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for 2"
      ],
      "metadata": {
        "id": "yB5PgfekwdM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_2 = logistic_regression(scaled_x_train2, scaled_x_test2, y_train_2, y_test_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLBnCGfXwlXD",
        "outputId": "91df31b2-f3f1-43cd-f358-e1180ac9f8d8"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy = 0.7966101694915254\n",
            "Testing precision = 0.6710526315789473\n",
            "Testing recall = 0.6891891891891891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 40% vs 60%"
      ],
      "metadata": {
        "id": "nQFEFpPOwzEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping from class 3 using ratio settings and creating New DataFrame"
      ],
      "metadata": {
        "id": "Ei1N2dklyNGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping 30%\n",
        "df_3 = drop_class_setting(drop_percent=0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMiMNoZRySIv",
        "outputId": "21f01c2c-5901-475a-a3eb-990f931f2ed0"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New 30% dropped class: \n",
            "0    809\n",
            "1    338\n",
            "Name: survived, dtype: int64\n",
            "\n",
            "Original class : \n",
            "0    809\n",
            "1    500\n",
            "Name: survived, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting new dataframe (train and test), imputing, encoding, and scaling"
      ],
      "metadata": {
        "id": "RVwfVJPpyprv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets split the new dataframe\n",
        "\n",
        "# splitting\n",
        "x_train_3, x_test_3, y_train_3, y_test_3 = split(df_3, 0.2)\n",
        "\n",
        "# imputing\n",
        "x_train3_imputed, x_test3_imputed = impute(x_train_3, x_test_3)\n",
        "\n",
        "# encoding and scaling\n",
        "scaled_x_train3, scaled_x_test3 = encode_scale(x_train3_imputed, x_test3_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PevV-YoysDs",
        "outputId": "0cded465-1ed3-4bad-813e-3f7ec0dd0c97"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of positive samples in whole data: 0.2946817785527463\n",
            "% of positive samples in train set: 0.29443838604143946\n",
            "% of positive samples in test set: 0.2956521739130435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for 3"
      ],
      "metadata": {
        "id": "PcI5iuzOzQ2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_3 = logistic_regression(scaled_x_train3, scaled_x_test3, y_train_3, y_test_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teIz_DCezUVp",
        "outputId": "b1033885-2bce-47fd-ba6c-bece1e3e118a"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy = 0.8521739130434782\n",
            "Testing precision = 0.8269230769230769\n",
            "Testing recall = 0.6323529411764706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egvnt6T3W-Ta"
      },
      "source": [
        "## 3. Analyse the class-wise accuracy. \n",
        "#### For each model, plot (bar plots) the class-wise accuracy, i.e., the accuracy for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Fo1_eaksW-Tb",
        "outputId": "9b3d6a29-96f7-401c-b32e-51bb08888d45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Class  Accuracy(%)\n",
              "0      1     0.819672\n",
              "1      2     0.796610\n",
              "2      3     0.852174"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54d74dc7-a6a5-4b52-93a2-85f32a66d777\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Accuracy(%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.819672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.796610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.852174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54d74dc7-a6a5-4b52-93a2-85f32a66d777')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54d74dc7-a6a5-4b52-93a2-85f32a66d777 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54d74dc7-a6a5-4b52-93a2-85f32a66d777');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ],
      "source": [
        "#### write your code \n",
        "# Lets create the array of classes\n",
        "import numpy as np\n",
        "imbalance = np.array([[1, 2, 3]]).T\n",
        "\n",
        "# Lets create the dataframe and plot the barplot\n",
        "df_accuracies = pd.DataFrame(imbalance, columns = ['Class'])\n",
        "df_accuracies[\"Accuracy(%)\"] = [accuracy_1, accuracy_2, accuracy_3]\n",
        "df_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxC9r8LFW-Tc"
      },
      "source": [
        "## 4. Report \n",
        "### Write a small report (few sentences) to discuss from your analysis, the impact of class imballance on logistic model's performance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU1XnqF2W-Tc"
      },
      "source": [
        "The performed significantly different in all three situations. on 30% it showed a little worse than 20% drop, however on 40% drop, it showed the best performance of all three. Although stratification was applied so we can say that the result is not biased."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}