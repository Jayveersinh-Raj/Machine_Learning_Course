{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayveersinh-Raj/Machine_Learning_IU_Labs/blob/main/Lab_3_self_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su3arr6KW-TN"
      },
      "source": [
        "### Lab-3 : Self-Practice\n",
        "\n",
        "#### In this week, your self-practice task will consist to analyze the impact of class imballance on the performance of the logistic regression model.\n",
        "\n",
        "#### Class imbalance is very common in real life. For example, in a classification problem to predict whether a person has a certain very rare disease, the dataset will always contain more negative samples than positive ones. This situation can have a significant impact on the performance of the model. You will analyze this situation in the case of the Titanic dataset used in the lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awQ5it11W-TU"
      },
      "source": [
        "### 1. Load the titanic dataset and <b>PLOT</b> the proportion of positive and negative samples (survived vs non survived)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "rZXUVCT2W-TV",
        "outputId": "9d231bfe-2548-4dae-846d-8b201cc8d0ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f41f9779350>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "### write your code here. Load the dataset and plot (barplot) proportion of each class \n",
        "df = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "# Below dataframe was printed to see the column name of the class\n",
        "# df.head()\n",
        "df[\"survived\"].value_counts().plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.survived.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu2Iu10PkIVU",
        "outputId": "f7c14ff4-5c9a-4110-f53b-3a503b31c7d8"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    809\n",
              "1    500\n",
              "Name: survived, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoriMit5W-TX"
      },
      "source": [
        "#### Preprocess the data as it has been done in the lab, feel free to adapt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC3oFY_YW-TY",
        "outputId": "53a503ae-f539-47ff-dcd0-c63e9995b87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1309 entries, 0 to 1308\n",
            "Data columns (total 9 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   survived  1309 non-null   int64  \n",
            " 1   pclass    1309 non-null   int64  \n",
            " 2   name      1309 non-null   object \n",
            " 3   sex       1309 non-null   object \n",
            " 4   age       1046 non-null   float64\n",
            " 5   sibsp     1309 non-null   int64  \n",
            " 6   parch     1309 non-null   int64  \n",
            " 7   fare      1308 non-null   float64\n",
            " 8   embarked  1307 non-null   object \n",
            "dtypes: float64(2), int64(4), object(3)\n",
            "memory usage: 92.2+ KB\n"
          ]
        }
      ],
      "source": [
        "#### preprocess the data\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `age`, `fare`, and `embarked` has 253, 2, and 1 missing values respectively so imputation is needed too, and we will also apply scaler.\n",
        "\n",
        "## And `name` would be removed as it is not necessary"
      ],
      "metadata": {
        "id": "0w9PtQLLbl0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split(df, test_size_split):\n",
        "\n",
        "   # removing name column\n",
        "   df = df.drop(['name'], axis = 1)\n",
        "   \n",
        "   # find and print the proportion of positive samples in data\n",
        "   print('% of positive samples in whole data:', sum(df['survived'] == 1) / len(df))\n",
        "   \n",
        "   # split data\n",
        "   x_train, x_test, y_train, y_test = train_test_split(df.loc[:, 'pclass':], df['survived'],\n",
        "                                                       test_size=test_size_split, stratify=df['survived'])\n",
        "   \n",
        "   # find and print the proportion of positive samples in train and test sets, make sure they are approx same\n",
        "   print('% of positive samples in train set:', sum(y_train== 1) / len(x_train))\n",
        "   print('% of positive samples in test set:', sum(y_test== 1) / len(x_test))\n",
        "   return x_train, x_test, y_train, y_test"
      ],
      "metadata": {
        "id": "-DDNZetlc2zN"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def impute(x_train, x_test):\n",
        "    # imputing missing values\n",
        "    imputer = SimpleImputer(strategy='most_frequent')\n",
        "    imputer.fit(x_train)\n",
        "    x_train = pd.DataFrame(imputer.transform(x_train), columns=x_train.columns)\n",
        "    x_test = pd.DataFrame(imputer.transform(x_test), columns=x_test.columns)\n",
        "    return x_train, x_test"
      ],
      "metadata": {
        "id": "jYKLtmLpcN-g"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding and scaling"
      ],
      "metadata": {
        "id": "Vnlzy-dpdnnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# one-hot-encode categorical features\n",
        "def ohe_new_features(df, features_name, encoder):\n",
        "    new_feats = encoder.transform(df[features_name])\n",
        "    # create dataframe from encoded features with named columns\n",
        "    new_cols = pd.DataFrame(new_feats, dtype=int, columns=encoder.get_feature_names(features_name))\n",
        "    new_df = pd.concat([df, new_cols], axis=1)    \n",
        "    new_df.drop(features_name, axis=1, inplace=True)\n",
        "    return new_df\n",
        "\n",
        "def encode_scale(x_train, x_test):\n",
        "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "    f_names = ['sex', 'embarked']\n",
        "    encoder.fit(x_train[f_names])\n",
        "    x_train = ohe_new_features(x_train, f_names, encoder)\n",
        "    x_test = ohe_new_features(x_test, f_names, encoder)\n",
        "    \n",
        "    # feature scaling\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(x_train)\n",
        "    x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n",
        "    x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
        "    return x_train, x_test"
      ],
      "metadata": {
        "id": "-46K-TZodsEN"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbxd9U8ZW-TY"
      },
      "source": [
        "## 2. Impact of class imballance. \n",
        "##### Now, you will `artificially` imbalance the dataset. From the original dataset, create different dataset with the following class representations (drop samples from one class): \n",
        "##### 1. 20% vs 80%\n",
        "##### 2. 30% vs 70%\n",
        "##### 3. 40% vs 60%\n",
        "\n",
        "## Split each data into train and test set as in the lab; train logistic regression model for each setting and report (PLOT) the accuracy, precision, and recall of each model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The logistic regression function that prints accuracy, precision, and recall and returns `acccuracy`"
      ],
      "metadata": {
        "id": "prmiBrqnnpCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "def logistic_regression(x_train, x_test, y_train, y_test):\n",
        "    clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
        "    y_test_pred = clf.predict(x_test)\n",
        "    \n",
        "    print('Testing accuracy = {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
        "    print('Testing precision = {}'.format(metrics.precision_score(y_test, y_test_pred)))\n",
        "    print('Testing recall = {}'.format(metrics.recall_score(y_test, y_test_pred)))\n",
        "\n",
        "    return metrics.accuracy_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "1eSIAr_xmuQw"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to drop according to setting ratio provided above"
      ],
      "metadata": {
        "id": "zVMK9KpMo_tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### write your code here \n",
        "def drop_class_setting(drop_percent):\n",
        "    to_be_removed = df[(df.survived == 1)].sample(frac=drop_percent, replace=True, random_state=42)\n",
        "    df_new = df.drop(to_be_removed.index)\n",
        "    print(f\"New 30% dropped class: \\n{df_new.survived.value_counts()}\")\n",
        "    print(f\"\\nOriginal class : \\n{df.survived.value_counts()}\")\n",
        "    return df_new"
      ],
      "metadata": {
        "id": "1KaHdwI3pJ6H"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 20% vs 80%"
      ],
      "metadata": {
        "id": "zkEG1gEiibPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping from class 1 using ratio settings and creating New DataFrame"
      ],
      "metadata": {
        "id": "2FHCcI4dpqUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGS-Zg50W-TZ",
        "outputId": "585c286e-971b-47b0-d1a6-6239f7880116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New 30% dropped class: \n",
            "0    809\n",
            "1    409\n",
            "Name: survived, dtype: int64\n",
            "\n",
            "Original class : \n",
            "0    809\n",
            "1    500\n",
            "Name: survived, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_1 = drop_class_setting(drop_percent=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting new dataframe (train and test), imputing, encoding, and scaling"
      ],
      "metadata": {
        "id": "Eb6qhht_qm3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets split the new dataframe\n",
        "\n",
        "# splitting\n",
        "x_train_1, x_test_1, y_train_1, y_test_1 = split(df_1, 0.2)\n",
        "\n",
        "# imputing\n",
        "x_train1_imputed, x_test1_imputed = impute(x_train_1, x_test_1)\n",
        "\n",
        "# encoding and scaling\n",
        "scaled_x_train1, scaled_x_test1 = encode_scale(x_train1_imputed, x_test1_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6dIzdlHqlH9",
        "outputId": "4a21dd8f-4814-4fd7-88b3-b066957b4560"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of positive samples in whole data: 0.33579638752052543\n",
            "% of positive samples in train set: 0.33572895277207393\n",
            "% of positive samples in test set: 0.3360655737704918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for 1"
      ],
      "metadata": {
        "id": "qPFTOXvJpuwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_1 = logistic_regression(scaled_x_train1, scaled_x_test1, y_train_1, y_test_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBIvzAydpojq",
        "outputId": "0c9932fc-a9c0-4aa9-b984-f48315ee7a6c"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy = 0.819672131147541\n",
            "Testing precision = 0.7375\n",
            "Testing recall = 0.7195121951219512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 30% vs 70%"
      ],
      "metadata": {
        "id": "269l_EXuoa4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping from class 2 using ratio settings and creating New DataFrame"
      ],
      "metadata": {
        "id": "qAQv0bvTwFsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping 30%\n",
        "df_2 = drop_class_setting(drop_percent=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd9jfNXwofF1",
        "outputId": "b423ab9a-f57f-47aa-844a-771113392f95"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New 30% dropped class: \n",
            "0    809\n",
            "1    371\n",
            "Name: survived, dtype: int64\n",
            "\n",
            "Original class : \n",
            "0    809\n",
            "1    500\n",
            "Name: survived, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting new dataframe (train and test), imputing, encoding, and scaling"
      ],
      "metadata": {
        "id": "ra8cMWdtoThn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets split the new dataframe\n",
        "\n",
        "# splitting\n",
        "x_train_2, x_test_2, y_train_2, y_test_2 = split(df_2, 0.2)\n",
        "\n",
        "# imputing\n",
        "x_train2_imputed, x_test2_imputed = impute(x_train_2, x_test_2)\n",
        "\n",
        "# encoding and scaling\n",
        "scaled_x_train2, scaled_x_test2 = encode_scale(x_train2_imputed, x_test2_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8zbYtVhoDmZ",
        "outputId": "67b745f3-4c40-45b2-89ca-03f9402fa388"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of positive samples in whole data: 0.31440677966101693\n",
            "% of positive samples in train set: 0.3146186440677966\n",
            "% of positive samples in test set: 0.3135593220338983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for 2"
      ],
      "metadata": {
        "id": "yB5PgfekwdM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_2 = logistic_regression(scaled_x_train2, scaled_x_test2, y_train_2, y_test_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLBnCGfXwlXD",
        "outputId": "91df31b2-f3f1-43cd-f358-e1180ac9f8d8"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy = 0.7966101694915254\n",
            "Testing precision = 0.6710526315789473\n",
            "Testing recall = 0.6891891891891891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 40% vs 60%"
      ],
      "metadata": {
        "id": "nQFEFpPOwzEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping from class 3 using ratio settings and creating New DataFrame"
      ],
      "metadata": {
        "id": "Ei1N2dklyNGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping 30%\n",
        "df_3 = drop_class_setting(drop_percent=0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMiMNoZRySIv",
        "outputId": "21f01c2c-5901-475a-a3eb-990f931f2ed0"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New 30% dropped class: \n",
            "0    809\n",
            "1    338\n",
            "Name: survived, dtype: int64\n",
            "\n",
            "Original class : \n",
            "0    809\n",
            "1    500\n",
            "Name: survived, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting new dataframe (train and test), imputing, encoding, and scaling"
      ],
      "metadata": {
        "id": "RVwfVJPpyprv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets split the new dataframe\n",
        "\n",
        "# splitting\n",
        "x_train_3, x_test_3, y_train_3, y_test_3 = split(df_3, 0.2)\n",
        "\n",
        "# imputing\n",
        "x_train3_imputed, x_test3_imputed = impute(x_train_3, x_test_3)\n",
        "\n",
        "# encoding and scaling\n",
        "scaled_x_train3, scaled_x_test3 = encode_scale(x_train3_imputed, x_test3_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PevV-YoysDs",
        "outputId": "0cded465-1ed3-4bad-813e-3f7ec0dd0c97"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of positive samples in whole data: 0.2946817785527463\n",
            "% of positive samples in train set: 0.29443838604143946\n",
            "% of positive samples in test set: 0.2956521739130435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for 3"
      ],
      "metadata": {
        "id": "PcI5iuzOzQ2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_3 = logistic_regression(scaled_x_train3, scaled_x_test3, y_train_3, y_test_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teIz_DCezUVp",
        "outputId": "b1033885-2bce-47fd-ba6c-bece1e3e118a"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy = 0.8521739130434782\n",
            "Testing precision = 0.8269230769230769\n",
            "Testing recall = 0.6323529411764706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egvnt6T3W-Ta"
      },
      "source": [
        "## 3. Analyse the class-wise accuracy. \n",
        "#### For each model, plot (bar plots) the class-wise accuracy, i.e., the accuracy for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Fo1_eaksW-Tb",
        "outputId": "56364e8c-f3d6-4a68-8daa-cd3b3d5dd303"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 201
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#### write your code \n",
        "# Lets create the array of classes\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "imbalance = np.array([[1, 2, 3]]).T\n",
        "\n",
        "# Lets create the dataframe and plot the barplot\n",
        "df_accuracies = pd.DataFrame(imbalance, columns = ['Setting'])\n",
        "df_accuracies[\"Accuracy(%)\"] = [accuracy_1, accuracy_2, accuracy_3]\n",
        "df_accuracies[\"Accuracy(%)\"].plot(kind = 'bar')\n",
        "plt.xlabel('Setting')\n",
        "plt.ylabel('Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxC9r8LFW-Tc"
      },
      "source": [
        "## 4. Report \n",
        "### Write a small report (few sentences) to discuss from your analysis, the impact of class imballance on logistic model's performance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU1XnqF2W-Tc"
      },
      "source": [
        "The performed significantly different in all three situations. on 30% it showed a little worse than 20% drop, however on 40% drop, it showed the best performance of all three. Although stratification was applied so we can say that the result is not biased."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}